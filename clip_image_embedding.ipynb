{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e58a45d",
   "metadata": {},
   "source": [
    "# CLIP (Ollama) Embedding inklusive Metadaten inklusive Kurzzusammenfassung der Bilder mit QwenVl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bbe0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull clip\n",
    "# ollama pull qwen3-vl:8b\n",
    "\n",
    "# pip install pillow tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "904f9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4b5356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurations Ordner und Ollama Clip Modell\n",
    "IMAGE_ROOT = Path(\"theorie\")  \n",
    "OUTPUT_FILE = \"image_embeddings.json\"\n",
    "\n",
    "CLIP_MODEL = \"clip\"                   # für Embeddings\n",
    "VISION_MODEL = \"qwen3-vl:8b\"          # für Bildbeschreibung (kurzer Inhalt)\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44e22291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle jpg Bilder finden\n",
    "def find_images(root: Path):\n",
    "    exts = [\".jpg\", \".jpeg\", \".png\"]\n",
    "    return [\n",
    "        p for p in root.rglob(\"*\")\n",
    "        if p.is_file() and p.suffix.lower() in exts\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "496d9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild laden & zu base64 konvertieren\n",
    "def to_b64(path: Path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "837ac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip Embedding berechnen \n",
    "def get_clip_embedding(b64_img: str):\n",
    "    payload = {\n",
    "        \"model\": CLIP_MODEL,\n",
    "        \"images\": [b64_img],\n",
    "        \"prompt\": \"\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=True)\n",
    "    embedding = None\n",
    "\n",
    "    for line in response.iter_lines():\n",
    "        if not line:\n",
    "            continue\n",
    "        j = json.loads(line.decode(\"utf-8\"))\n",
    "        if \"embedding\" in j:\n",
    "            embedding = j[\"embedding\"]\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34aa197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen3-VL (Ollama-LLM): Bildinhalt automatisch beschreiben\n",
    "\n",
    "def describe_image_qwen(b64_img: str):\n",
    "    prompt = (\n",
    "        \"Beschreibe dieses handschriftliche Mathematikbild sehr kurz und präzise. \"\n",
    "        \"Gib nur eine kurze Zusammenfassung, z. B. 'Lineare Gleichung', 'Integralaufgabe', \"\n",
    "        \"'Graph der Normalverteilung', 'Matrixmultiplikation', 'Ableitung einer Funktion'. \"\n",
    "        \"Maximal 1–2 Sätze.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": VISION_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"images\": [b64_img]\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=True)\n",
    "    summary = \"\"\n",
    "\n",
    "    for line in response.iter_lines():\n",
    "        if not line:\n",
    "            continue\n",
    "        j = json.loads(line.decode(\"utf-8\"))\n",
    "        if \"response\" in j:\n",
    "            summary += j[\"response\"]\n",
    "\n",
    "    return summary.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6a014",
   "metadata": {},
   "source": [
    "### Main pipeline: Embedding mit Metadaten & LLM Zusammenfassungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61d71540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Bilder: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 428/428 [00:06<00:00, 67.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FERTIG – gespeichert in: image_embeddings.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    images = find_images(IMAGE_ROOT)\n",
    "    print(\"Gefundene Bilder:\", len(images))\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for img in tqdm(images, desc=\"Embedding\"):\n",
    "        try:\n",
    "            b64 = to_b64(img)\n",
    "\n",
    "            # 1. Embedding\n",
    "            emb = get_clip_embedding(b64)\n",
    "        \n",
    "\n",
    "            # 2. Kurzbeschreibung (Qwen3-VL)\n",
    "            summary = describe_image_qwen(b64)\n",
    "\n",
    "            # 3. Metadaten pro Bild\n",
    "            out.append({\n",
    "                \"embedding\": emb,\n",
    "                \"metadata\": {\n",
    "                    \"path\": str(img),\n",
    "                    \"folder\": str(img.parent),\n",
    "                    \"filename\": img.name,\n",
    "                    \"summary\": summary,\n",
    "                    \"type\": \"image\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {img}: {e}\")\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\") as f:\n",
    "        json.dump(out, f, indent=2)\n",
    "\n",
    "    print(\"FERTIG – gespeichert in:\", OUTPUT_FILE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05937b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc038a64",
   "metadata": {},
   "source": [
    "### Hauptprozess: Basic Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7990596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef main():\\n    images = find_all_images(IMAGE_ROOT)\\n    print(f\"Gefundene Bilder: {len(images)}\")\\n\\n    results = []\\n\\n    for img_path in tqdm(images, desc=\"Embedding-Bilder\"):\\n        try:\\n            b64 = image_to_base64(img_path)\\n            emb = get_clip_embedding(b64)\\n\\n            # Metadaten\\n            metadata = {\\n                \"path\": str(img_path),\\n                \"folder\": str(img_path.parent),\\n                \"filename\": img_path.name,\\n                \"type\": \"image\",\\n                \"modality\": \"vision\",\\n            }\\n\\n            results.append({\\n                \"embedding\": emb,\\n                \"metadata\": metadata,\\n            })\\n\\n        except Exception as e:\\n            print(f\"Fehler bei {img_path}: {e}\")\\n\\n    # Speichern\\n    with open(OUTPUT_FILE, \"w\") as f:\\n        json.dump(results, f, indent=2)\\n\\n    print(f\"\\nFERTIG! Embeddings gespeichert in: {OUTPUT_FILE}\")\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def main():\n",
    "    images = find_all_images(IMAGE_ROOT)\n",
    "    print(f\"Gefundene Bilder: {len(images)}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for img_path in tqdm(images, desc=\"Embedding-Bilder\"):\n",
    "        try:\n",
    "            b64 = image_to_base64(img_path)\n",
    "            emb = get_clip_embedding(b64)\n",
    "\n",
    "            # Metadaten\n",
    "            metadata = {\n",
    "                \"path\": str(img_path),\n",
    "                \"folder\": str(img_path.parent),\n",
    "                \"filename\": img_path.name,\n",
    "                \"type\": \"image\",\n",
    "                \"modality\": \"vision\",\n",
    "            }\n",
    "\n",
    "            results.append({\n",
    "                \"embedding\": emb,\n",
    "                \"metadata\": metadata,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {img_path}: {e}\")\n",
    "\n",
    "    # Speichern\n",
    "    with open(OUTPUT_FILE, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"\\nFERTIG! Embeddings gespeichert in: {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45044c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0565be",
   "metadata": {},
   "source": [
    "Vectorstore am besten Chorma wsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb3966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f03a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
